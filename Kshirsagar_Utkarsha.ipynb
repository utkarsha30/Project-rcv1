{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required for project\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, hamming_loss,precision_score, recall_score\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the data for rcv1_data set\n",
    "rcv1 = fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "\n",
    "# Extract features (X) and target labels (y) from the dataset\n",
    "X = rcv1.data\n",
    "y = rcv1.target\n",
    "# Specify the number of samples for training and testing\n",
    "num_train_samples = 7000\n",
    "num_test_samples = 3000\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=num_train_samples, test_size=num_test_samples, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and X_train to dense arrays\n",
    "y_train = y_train.toarray()\n",
    "X_train = X_train.toarray()\n",
    "# Convert y_test and X_test to dense arrays\n",
    "X_test = X_test.toarray()\n",
    "y_test = y_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature names for both training and testing sets\n",
    "feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "feature_df_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "feature_names = [f\"feature_{i}\" for i in range(X_test.shape[1])]\n",
    "feature_df_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# Create DataFrames for training targets and testing targets\n",
    "target_names = rcv1.target_names\n",
    "target_df_train = pd.DataFrame(y_train, columns=target_names)\n",
    "target_df_test = pd.DataFrame(y_test, columns=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with all zero values in the training features\n",
    "zero_columns = feature_df_train.columns[feature_df_train.eq(0).all()]\n",
    "\n",
    "# Drop columns with all zero values from training and testing feature DataFrames\n",
    "feature_df_train.drop(columns=zero_columns, inplace=True)\n",
    "feature_df_test.drop(columns=zero_columns, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with all zero values in the training targets\n",
    "zero_columns = target_df_train.columns[target_df_train.eq(0).all()]\n",
    "\n",
    "# Drop columns with all zero values from training and testing target DataFrames\n",
    "target_df_train.drop(columns=zero_columns, inplace=True)\n",
    "target_df_test.drop(columns=zero_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(feature_df_train)\n",
    "X_test_scaled = scaler.transform(feature_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing PCA\n",
    "pca = PCA(n_components=0.95)  # Keeping 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Performance for SVM with PCA and gradient descent  :\n",
      "Accuracy: 51.93%\n",
      "Hamming Loss: 1.13%\n",
      "Weighted Precision: 89.26%\n",
      "Weighted Recall: 74.67%\n"
     ]
    }
   ],
   "source": [
    "# 1. linear SVM with PCA and gradient descent \n",
    "# Initialize the SGDClassifier\n",
    "sgd_classifier = SGDClassifier(loss='hinge',  # For linear SVM\n",
    "                               alpha=0.0001,  # Regularization strength\n",
    "                               max_iter=1000,  # Number of iterations\n",
    "                               tol=1e-3,  # Tolerance to declare convergence\n",
    "                               random_state=42)\n",
    "\n",
    "# Wrap the classifier with MultiOutputClassifier for multi-label classification\n",
    "svm_model = MultiOutputClassifier(sgd_classifier)\n",
    "\n",
    "\n",
    "# Train the model on the training set\n",
    "svm_model.fit(X_train_pca, target_df_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "# Evaluate the performance\n",
    "hamming_loss_value = hamming_loss(target_df_test, y_pred)\n",
    "precision = precision_score(target_df_test, y_pred, average='micro')\n",
    "recall = recall_score(target_df_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(target_df_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics  \n",
    "print(\"Metrics Performance for SVM with PCA and gradient descent  :\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value * 100:.2f}%\")\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted Recall: {recall * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Performance for Random forest with PCA :\n",
      "Accuracy: 11.03%\n",
      "Hamming Loss: 2.57%\n",
      "Weighted Precision: 89.29%\n",
      "Weighted Recall: 25.38%\n"
     ]
    }
   ],
   "source": [
    "# 2.Random forest with PCA\n",
    "# Create a RandomForestClassifier instance\n",
    "rf_classifier_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier on the training data with PCA-transformed features\n",
    "rf_classifier_pca.fit(X_train_pca, target_df_train)\n",
    "\n",
    "# Make predictions on the test set with PCA-transformed features\n",
    "y_pred = rf_classifier_pca.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the performance\n",
    "hamming_loss_value = hamming_loss(target_df_test, y_pred)\n",
    "precision = precision_score(target_df_test, y_pred, average='micro')\n",
    "recall = recall_score(target_df_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(target_df_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics  \n",
    "print(\"Metrics Performance for Random forest with PCA :\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value * 100:.2f}%\")\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted Recall: {recall * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Performance for Logistic Regression with PCA and gradient descent :\n",
      "Accuracy: 5.63%\n",
      "Hamming Loss: 2.35%\n",
      "Weighted Precision: 95.42%\n",
      "Weighted Recall: 30.26%\n"
     ]
    }
   ],
   "source": [
    "# 3. Linear Regression with PCA and gradient descent\n",
    "# Create an SGDClassifier for Logistic Regression\n",
    "sgd_classifier = SGDClassifier(loss='log_loss', alpha=0.01, max_iter=1000, random_state=42)\n",
    "\n",
    "# Wrap the classifier with MultiOutputClassifier for multi-label classification\n",
    "logistic_regression_model = MultiOutputClassifier(sgd_classifier)\n",
    "\n",
    "# Train the model on the training set\n",
    "logistic_regression_model.fit(X_train_pca, target_df_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = logistic_regression_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the performance\n",
    "hamming_loss_value = hamming_loss(target_df_test, y_pred)\n",
    "precision = precision_score(target_df_test, y_pred, average='micro')\n",
    "recall = recall_score(target_df_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(target_df_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics  \n",
    "print(\"Metrics Performance for Logistic Regression with PCA and gradient descent :\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value * 100:.2f}%\")\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted Recall: {recall * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 2.0}\n",
      "Metrics Performance for Naive Bayse with hyper parameter tunning :\n",
      "Accuracy: 25.27%\n",
      "Hamming Loss: 2.53%\n",
      "Weighted Precision: 64.22%\n",
      "Weighted Recall: 52.91%\n"
     ]
    }
   ],
   "source": [
    "# 4.Naive Bayse with hyper parameter tunning\n",
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(nb_classifier, param_grid, scoring='accuracy')\n",
    "\n",
    "# Create a MultiOutputClassifier with the grid search\n",
    "nb_model = MultiOutputClassifier(grid_search)\n",
    "\n",
    "# Fit the model on the training data\n",
    "nb_model.fit(X_train_scaled, target_df_train)\n",
    "\n",
    "# Access the best hyperparameters from the GridSearchCV object\n",
    "best_params = nb_model.estimators_[0].best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance\n",
    "hamming_loss_value = hamming_loss(target_df_test, y_pred)\n",
    "precision = precision_score(target_df_test, y_pred, average='micro')\n",
    "recall = recall_score(target_df_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(target_df_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics  \n",
    "print(\"Metrics Performance for Naive Bayse with hyper parameter tunning :\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value * 100:.2f}%\")\n",
    "print(f\"Weighted Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Weighted Recall: {recall * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
